\chapter{Higher mutation rates and heavy tailed mutations}\label{ch:heavyMut}

In this chapter different ways to change the mutation rate for EAs are discussed so that they flip more bits in expectation.

\section{Algorithms}
For the (1+1) EA changing the expected amount of flipped bits per step can be done easily.
By changing the mutation rate $1/n$ to $c/n$ for any constant $c$ the algorithm now flips $n\cdot c/n=c$ bits in expectation.
\begin{algorithm}[bt]
      \caption{\textsc{(1+1) EA with static mutation rate}}\label{alg:EA_SM}

      % Some settings
      \DontPrintSemicolon %dontprintsemicolon
      \SetFuncSty{textsc}

      % The algorithm
      \BlankLine
      choose x uniform from ${\{0,1\}}^n$\;
      \While{$x$ not optimal}
      {
      $x' \leftarrow x$\;
      flip every bit of $x'$ with probability $c/n$\;
      {
      \If{$f(x') \le f(x)$}
      {
            $x \leftarrow x'$\;
      }
      }
      }
\end{algorithm}

For the RLS it is not that simple, as the RLS chooses a random bit and flips it.
Instead of flipping c bits in every step there should be the possibility to flip different amounts of bits in every step.
The standard RLS chooses a random neighbour with hamming distance one.
So the variant of the RLS could simply choose neighbours that have a hamming distance larger than one.
The selection should still be uniform random to keep the idea of the RLS intact.
One possible way is to choose a random neighbour with hamming distance $\le k$.
The amount of neighbours with hamming distance $y$ is given by $\binom{n}{y}$.
For $k=4$, this results in $n$ neighbours with hamming distance 1, $n(n-1)/2$ neighbours with hamming distance 2, $n(n-1)(n-2)/6$
and $n(n-1)(n-2)(n-3)/24$.
The probability to choose a random neighbour with hamming distance $y \le k$ is given by
\[P(RLS-N_k\text{ flips y bits}) = \frac{\binom{n}{y}}{\sum_{i=1}^k \binom{n}{i}} = \frac{\mathcal{O}(n^y)}{\sum_{i=1}^k \mathcal{O}(n^i)}
      = \frac{\mathcal{O}(n^y)}{\mathcal{O}(n^k)} = \mathcal{O}(n^{y-k}) = \mathcal{O}(\frac{1}{n^{k-y}})\]
This variant of the RLS is likely to choose a neighbour with hamming distance k as the number of neighbours with hamming
distance $k$ rises with $k$ for $k \le n/2$.
The probability of flipping only one bit is $\mathcal{O}(\frac{1}{n^{k-1}})$.
For some inputs flipping only one bit might be more optimal which is rather unlikely for this variant of the RLS.\newline
\begin{algorithm}[bt]
      \caption{\textsc{RLS-N}}\label{alg:rlsN}

      % Some settings
      \DontPrintSemicolon %dontprintsemicolon
      \SetFuncSty{textsc}

      % The algorithm
      \BlankLine
      choose x uniform from ${\{0,1\}}^n$\;
      \While{$x$ not optimal}
      {
      $x' \leftarrow \text{uniform random neighbour of x with hamming distance} \le k$\;
      {
      \If{$f(x') \le f(x)$}
      {
            $x \leftarrow x'$\;
      }
      }
      }
\end{algorithm}

An alternative way of changing the RLS is to first choose $y \in \{1, \dots, k\}$ uniform random and then choose a neighbour with hamming distance $y$ uniform random.
Here the probability of flipping $y \le k$ bits is given by $1/k$, so the algorithm is much more likely to choose to flip only one bit.

\begin{algorithm}[bt]
      \caption{\textsc{RLS-R}}\label{alg:rlsR}

      % Some settings
      \DontPrintSemicolon %dontprintsemicolon
      \SetFuncSty{textsc}

      % The algorithm
      \BlankLine
      choose x uniform from ${\{0,1\}}^n$\;
      \While{$x$ not optimal}
      {
      $y \leftarrow \text{uniform random value }\in \{1,\dots,k\}$\;
      $x' \leftarrow \text{uniform random neighbour of x with hamming distance } y$\;
      {
      \If{$f(x') \le f(x)$}
      {
            $x \leftarrow x'$\;
      }
      }
      }
\end{algorithm}

Both variants of the RLS change at most $k$ bits in each step and therefore only a constant amount of bits.
For the (1+1) EA the algorithm will also flip mostly $\mathcal{O}(c)$ bits which is also constant.
So neither of the new variants is likely to change up to $\mathcal{O}(n)$ bits.
Quinzan \textit{et al.} therefore introduced another mutation operator in~\cite{friedrich2018evolutionary} called $pmut_\beta$.
This operator chooses $k$ from a powerlaw distribution with parameter $\beta$ and then $k$ uniform random bits are flipped.
This algorithm will mostly flip a small number of bits but occasionally up to n bits.
Distributions like this are called heavy tailed mutations because their tail is not bounded exponentially.