\section{OneMax Equivalent for PARTITION}
This kind of input is more or less equivalent to the OneMax problem. All values except the last are either 1 or follow any distribution. The last value is the sum of all other values. The optimal solution is therefore the 000\dots01 or
the 111\dots01 string. So the best solution is almost identical to OneMax/ZeroMax depending on the value of the last bit.\newline
For OneMax the mutation rate of 1/n is proven to be optimal for the (1+1) EA~\cite{witt2013tight}.
This should also hold for this input.
The RLS variants should also perform worse than the standard RLS.
The higher the value for $\beta$ the better the $pmut_\beta$ mutation should perform.
With some testing with various algorithm variants it looked like the last bit was only flipped at most once for every input.
There was only one case where it was flipped twice, but it was never flipped more than twice per run.\newline
For some experiments not all 1000 repetitions were executed as there was a clear tendency which of the algorithms performs better.
\subsection{RLS Comparison}


\input{tables/onemax/rls_compare.tex}

As expected the standard RLS reaches an optimal solution the fastest.
It also reaches the optimal value for every instance.
The RLS-R variants need more iterations to find an optimal solution.
By looking at the average values more closely it seems like the average number of steps is roughly $25,000 + 70,000k \pm 5,000$.
The standard RLS is equivalent to RLS-R or RLS-N with $k=1$.
So the value of $k=1$ seems to be optimal for the RLS variants too.
The RLS-N variants on the other hand do not reach one of the two optimal solutions in any run.
This is most likely caused by their very low possibility of flipping only one bit in a single step.
They would eventually reach the optimal solution as well, but this would take to long.
The probability of flipping only one bit in a step is $\mathcal{O}(n^{1-k})$ which results in a single bit flip every $\mathcal{O}(n^{k-1})$ steps in expectation.
Because the fitness can only improve for OneMax making steps flipping more bits does not harm the fitness.
The bound for OneMax is $\mathcal{O}(nlogn)$ and with the previous result the expected number of steps is bounded by
$\mathcal{O}(n\cdot\mathcal{O}(n^{k-1})\cdot \log(n\cdot\mathcal{O}(n^{k-1}))) 
=\mathcal{O}(n^{k-1+1}\cdot (k-1+1)\cdot\log(n))
=\mathcal{O}(kn^{k}\cdot\log(n))$
This problem is not equivalent to OneMax, as a flip of the bit with the highest value inverts the fitness function to ZeroMax but the result might still hold as the bound for the standard RLS for this input is the same as for the RLS on OneMax.
\subsection{(1+1) EA Comparison}


\input{tables/onemax/ea_compare.tex}

This experiment was terminated after 224 runs of the algorithms, as the results were already clear enough.
For this input the same as for OneMax holds. 
The static mutation rate $p_m=1/n$ is the optimal value and the performance of the (1+1) EA decreases with rising mutation rate.
Only for $p_m\le3/n$ the (1+1) EA managed to find one of the two optimal solutions in $10*nln(n)$ steps.
With mutation rate $p_m=4/n$ the (1+1 EA) only managed to find the optimal solution in about 55 \% of the inputs.
The remaining mutation rates did not manage to find an optimal solution in any of the runs.
Another interesting fact is the average number of bits flipped in a successful step.
For the other inputs the overall average number of bits flipped in any step was mostly the same as for the average value of the successful steps. Here this is not the case.
All mutation rates flipped fewer bits in the successful steps then in the average step.
The only exception is the standard mutation rate which is caused by the steps where the algorithm would flip no bit.
This decreases the number of the average case but not of the successful steps as those were skipped.
\subsection{pmut Comparison}
The results for the $pmut$ operator are pretty similar to the results for the (1+1) EA and the RLS.
The parameter $\beta=-3.25$ which flips the least bits on average finds the solution the fastest.
The other values for $\beta$ increase the time needed for finding one of the two optimums with increasing value for $\beta$ (decreasing in the absolute value).
All variants find an optimum in every run except for $\beta=-1.25$ which has a much higher value for the number of flipped bits per steps.
The average number for the number of bits flipped in a successful mutation is much lower than for the other inputs especially for the higher (absolute lower) values for $\beta$.
For the binomial and geometric input the successful average was around 100 for $\beta=-1.25$ but for the OneMax equivalent it was only at 5.

\input{tables/onemax/pmut_compare.tex}



\subsection{Comparison of the best variants}


\input{tables/onemax/best.tex}

The results for this experiment are as expected.
All three algorithms find the optimal value within the time limit.
The RLS performs better than the (1+1) EA because it does only single bit flips.
The $pmut_{-3.25}$ performs better than the standard (1+1) EA although flipping more bits on average.
This is most likely cause by the few steps where $pmut$ flips many bits which increase the average.
But $pmut$ most likely chooses to flip only one bit more often as the (1+1) EA.\newline
For this comparison neither of the algorithms failed to find one of the two optimal solutions.
The following table lists the amount of iterations the algorithms needed to find an optimal solution.

\input{tables/oneMax/multipleN_avg.tex}

The RLS performs the best closely follow by both $pmut$ variants.
The standard (1+1) EA performs a bit worse than the other three algorithms and approaches $en\ln(n)$ instead of staying close to $n\ln(n)$.

\begin{figure}[h]
      \caption{Runtime for OneMax equivalent with a $n\ln(n)$ scale}
      \centering
      \includegraphics[width=0.7\textwidth]{figures/images/oneMaxMultipleN.png}\label{fig:onemaxNlogNBound}
\end{figure}

In a previous chapter the $\mathcal{O}(nlogn)$ bound was proven for the (1+1) EA and the RLS.
This seems to hold in practice.
